{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cheatsheet_Function_Approximation1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "I-Kp6Cme-ECb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Function Approximation and Properties \n",
        "\n",
        "Let's consider a system which is represented by a Transfer Function \n",
        "\n",
        "![System1](https://i.paste.pics/d53c4340e5a9e06846352cf0a7000bbb.png)\n",
        "\n",
        "with \n",
        "- $\\{X_{i}\\}$ : Set of Scalar Input modeled as Random Variables \n",
        "- $Y$ : Scalar Output \n",
        "\n",
        "Its math representation as $f : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ \n",
        "\n",
        "$$ Y = f( \\{X_{i}\\}_{i=1,...,n} ) $$\n",
        "\n",
        "\n",
        "\n",
        "# Approximation around a specific point \n",
        "\n",
        "Let's now assume we want to work on a simplified version of the system, around a certain specific input value $ x_{0} =\\{x_{0,i}\\}_{i=1,...,n} $\n",
        "\n",
        "Let's also assume we are satisfied with first order approximation which is expressed using Taylor Expansion blocked at the first term \n",
        "\n",
        "$$ Y \\simeq Y^{(1)} = f(x_{0}) + \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial X_{i}} (X_{i} - x_{0,i}) = a_{0} + \\sum_{i=1}^{n} a_{i} (X_{i} - x_{0,i}) $$\n",
        "\n",
        "## Observations \n",
        "\n",
        "- While $f : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ note that $\\frac{\\partial f}{\\partial X_{i}} : \\mathbb{R} \\rightarrow \\mathbb{R}$ \n",
        "- the $\\Delta X_{i} = X_{i} - x_{0,i}$ is just a matter of operating a translation on the randon variable \n",
        "- the $a_{0}$ is punctual forward function evaluation \n",
        "  - e.g. in a NN scenario, it consists of a full forward pass from input to output \n",
        "- the $\\{a_{i}\\}_{i=1,...,n} = \\frac{\\partial f}{\\partial X_{i}}$ is an evaluation of each function derivative branch \n",
        "  - e.g. in NN scenario, the function derivative branches in an automatic differentiation framework can be computed once in closed form at network definition time and multiple (lazy) evaluations are performed at training time \n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "id": "pcoo0rLtA1Dt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Uncertainty Propagation \n",
        "\n",
        "It is interesting to derive how uncertainty propagate from the initial definition to the first order approximation \n",
        "\n",
        "## Mean \n",
        "\n",
        "- Linear Approximation makes the Uncertainty become Gaussian (Theoretical result)\n",
        "- The moments values are \n",
        "\n",
        "$$ \\bar y^{(1)} = E[Y^{(1)}] = E[a_{0}] + E[ \\sum_{i=1}^{n} a_{i} \\Delta X_{i}] = a_{0} + a_{i} E[\\Delta X_{i}] $$\n",
        "\n",
        "- If the translation has been operated in $a_{0}$ then $E[\\Delta X_{i}] = 0$\n",
        "\n",
        "\n",
        "## Variance \n",
        "\n",
        "Let's assume $E[\\Delta X_{i}] = 0$ so \n",
        "\n",
        "$$ E[\\left((Y^{(1)}) - \\bar y^{(1)}\\right)^{2}] = \\sum_{i=1}^{n} a_{i}^{2} \\sigma_{i}^{2} + \\sum_{i,j \\quad i \\neq j}^{n,n} a_{i}a_{j} \\sigma_{i,j} $$ \n",
        "\n",
        "with \n",
        "- the $\\sigma_{i,j} = E[\\Delta X_{i} \\Delta X_{j}]$\n",
        "- the $\\sigma_{i}^{2} = E[\\Delta X_{i}^{2}]$\n",
        "\n",
        "Appunto \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "TjqeU9kD-BkZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
